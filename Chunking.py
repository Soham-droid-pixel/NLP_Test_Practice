import nltk
nltk.download('punkt_tab')
nltk.download('averaged_perceptron_tagger_eng')

sentence="Donald Trump was born in Queens, New York."
tokens=nltk.word_tokenize(sentence)
pos_taggers=nltk.pos_tag(tokens)

grammar="NP:{<DT>?<JJ>*<NNP>+}"
chunk_parser=nltk.RegexpParser(grammar)
tree=chunk_parser.parse(pos_taggers)
tree.draw()

print("POS tags:",pos_taggers)
print("Chunks:",tree)
"""Tokenize sentence ‚Üí tokens

Assign POS tags ‚Üí tags

Define grammar (what kind of phrases to group)

Parse tags into phrases (NP chunks here)

Show output as text or tree

"""
"""Perfect üëç Let‚Äôs create **clear notes** and a **memory-friendly algorithm** so you can recall this anytime.

---

## üìí **NOTES ‚Äì NLTK Chunking Process**

---

### **1Ô∏è‚É£ Key Concepts**

* **Chunking** ‚Üí Grouping words into meaningful phrases (NP = Noun Phrase, VP = Verb Phrase, PP = Prepositional Phrase).
* **POS Tags** are needed before chunking (because chunking patterns are based on word categories).
* **Grammar Rules** are written using regex-like syntax for POS tags.

---

### **2Ô∏è‚É£ Common POS Tags**

| POS Tag      | Meaning                | Example         |
| ------------ | ---------------------- | --------------- |
| DT           | Determiner             | the, a, an      |
| JJ           | Adjective              | big, beautiful  |
| NNP          | Proper noun (singular) | London, Trump   |
| NNS          | Noun plural            | cities, books   |
| VB, VBD, VBN | Verb forms             | eat, was, eaten |
| IN           | Preposition            | in, on, at      |

---

### **3Ô∏è‚É£ Grammar Syntax**

**General format:**

```
LABEL: {<POS_TAG_PATTERN>}
```

Examples:

* `NP: {<DT>?<JJ>*<NNP>+}` ‚Üí Optional determiner, adjectives, and one or more proper nouns
* `VP: {<VB.*><NP|PP>*}` ‚Üí Verb followed by noun or prepositional phrases
* `PP: {<IN><NP>}` ‚Üí Preposition followed by noun phrase

---

### **4Ô∏è‚É£ Steps to Perform Chunking**

1. **Tokenize sentence**
   `nltk.word_tokenize(sentence)`
2. **POS Tagging**
   `nltk.pos_tag(tokens)`
3. **Define Grammar**
   `grammar = "NP: {<DT>?<JJ>*<NNP>+}"`
4. **Create Parser**
   `parser = nltk.RegexpParser(grammar)`
5. **Parse sentence**
   `tree = parser.parse(pos_tags)`
6. **View results**
   `tree.draw()` or `print(tree)`

---

---

## üß† **ALGORITHM TO REMEMBER (Memory Trick)**

Think of it as **T P G P P V** = *"The Python Grammar Parses Phrases Visually"*

1Ô∏è‚É£ **T** ‚Üí Tokenize (`word_tokenize`)
2Ô∏è‚É£ **P** ‚Üí POS tag (`pos_tag`)
3Ô∏è‚É£ **G** ‚Üí Grammar (write your chunking rules)
4Ô∏è‚É£ **P** ‚Üí Parser (RegexpParser with grammar)
5Ô∏è‚É£ **P** ‚Üí Parse (apply parser to tagged sentence)
6Ô∏è‚É£ **V** ‚Üí View (tree.draw or print)

---

üí° **Quick Example (NP only)**

```python
tokens = nltk.word_tokenize("Donald Trump was born in New York.")
tags = nltk.pos_tag(tokens)
grammar = "NP: {<DT>?<JJ>*<NNP>+}"
parser = nltk.RegexpParser(grammar)
tree = parser.parse(tags)
tree.draw()
```

---

üëâ If you want, I can create a **one-page visual cheat sheet** (with NP, VP, PP grammar + diagram) so you can quickly revise chunking rules before practice.
Do you want that?
"""
# ===== ALGORITHM =====
# 1. Tokenize + POS tag sentence
# 2. Define chunk grammar for NPs (e.g. <DT>?<JJ>*<NNP>+)
# 3. Create RegexpParser
# 4. Parse tags & visualize/print

# ===== EXAM POINTS =====
# * Chunking groups words (e.g. noun phrases)
# * Grammar uses POS tags: DT=det, JJ=adj, NNP=proper noun
# * tree.draw() (optional in lab)
