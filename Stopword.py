import nltk
from nltk.corpus import stopwords
import spacy
nltk.download('punkt')
nltk.download('stopwords')

text="This is an example sentence, showing the effect of stopword removal."
#NLTK:
nltk_tokens=nltk.word_tokenize(text)
nltk_stopwords=set(stopwords.words('english'))
nltk_filtered=[word for word in nltk_tokens if word.lower() not in nltk_stopwords]
#Spacy:
nlp=spacy.load('en_core_web_sm')
spacy_filtered=[token.text for token in nlp(text) if not token.is_stop]
print("Original word count",len(text))
print("After NLTK Stopword removal:",nltk_filtered)
print("After Spacy Stopword Removal:",spacy_filtered)
"""Got it üëç Let‚Äôs make this **super revision-friendly** so you can quickly recall for the exam without stress.

---

# üìå **Stopword Removal ‚Äì NLTK vs SpaCy (Revision)**

---

## **üîπ NLTK Approach**

**Steps (Memory Trick ‚Üí `T S F`)**

1. **T** ‚Üí Tokenize: `nltk.word_tokenize(text)`
2. **S** ‚Üí Stopwords set: `stopwords.words('english')`
3. **F** ‚Üí Filter: `[w for w in tokens if w.lower() not in stopwords]`

**Code:**

```python
import nltk
from nltk.corpus import stopwords
nltk.download('punkt')
nltk.download('stopwords')

tokens = nltk.word_tokenize(text)
stop_set = set(stopwords.words('english'))
filtered_nltk = [w for w in tokens if w.lower() not in stop_set]
```

---

## **üîπ SpaCy Approach**

**Steps (Memory Trick ‚Üí `N F`)**

1. **N** ‚Üí NLP pipeline: `nlp = spacy.load(...)`
2. **F** ‚Üí Filter with `token.is_stop`

**Code:**

```python
import spacy
nlp = spacy.load("en_core_web_sm")

filtered_spacy = [t.text for t in nlp(text) if not t.is_stop]
```

---

# üß† **Memory Hack**

Think:

> **‚ÄúNLTK ‚Üí Manual Check | SpaCy ‚Üí Auto Check‚Äù**

* NLTK = *you check word in stopwords set*
* SpaCy = *SpaCy checks with `token.is_stop`*

Or remember:

> **‚ÄúNLTK = 3 Steps (T-S-F) | SpaCy = 2 Steps (N-F)‚Äù**

---

# ‚ö° **Mini Revision Table**

| Feature         | NLTK                         | SpaCy                    |
| --------------- | ---------------------------- | ------------------------ |
| Tokenization    | `word_tokenize()`            | `nlp(text)`              |
| Stopword Source | `stopwords.words('english')` | Built-in `token.is_stop` |
| Filtering Logic | Manual list comprehension    | Attribute check          |

---

üëâ Question: Do you want me to give you a **one-page diagram (flow chart)** that visually shows NLTK vs SpaCy steps side by side (2 arrows each) so it‚Äôs stuck in your head? That would be exam gold.
"""